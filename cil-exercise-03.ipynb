{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Exercise session notes\n",
    "\n",
    "SVD is a genralization of eigenvalue decomposition.\n",
    "\n",
    "Given\n",
    "\n",
    "$$ A = U \\cdot D \\cdot V^{T} $$\n",
    "\n",
    "it holds that\n",
    "\n",
    "$$ \\left\\{ \\begin{array}{l}\n",
    "    A \\cdot V_i = d_i \\cdot u_i\\\\\n",
    "    A^{T} \\cdot U_i = d_i \\cdot v_i\n",
    "\\end{array}\\right. \n",
    "\\iff \n",
    "\\left\\{ \\begin{array}{l}\n",
    "    A \\cdot A^{T} \\cdot U_i = d_{i}^{2} u_{i} \\\\\n",
    "    A^{T} \\cdot A \\cdot V_i = d_{i}^{2} v_{i} \n",
    "\\end{array}\\right. .$$\n",
    "\n",
    "Exercise: prove that $r(\\tilde{A}) = 2$, where $\\tilde{A}_2 = U_2 \\cdot D_2 \\cdot V_2^T$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1 (SVD Theory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import copy\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A = np.array([\n",
    "        [8, 7,      1, np.NaN, 4],\n",
    "        [9, 7,      2, 5,      6],\n",
    "        [1, 4,      9, np.NaN, 3],\n",
    "        [3, np.NaN, 8, 5,      4],\n",
    "        [np.NaN, 3, np.NaN, 9, 9],\n",
    "        [5, 1, 4, 10, np.NaN]\n",
    "    ])\n",
    "\n",
    "print(A.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$A \\in \\mathbb{R}^{M \\times N}$.\n",
    "\n",
    "1. $ K = AA^{T}, K \\in \\mathbb{R}^{M \\times M} $ indicates row-row correlations (movie-movie similarities). Every element (i, j) is just the dot product between movies i and j. Could consider using cosine similarity instead of the dot product in order not to get distracted by the absolute rating when computing similarities (movie pairs with higher ratings lead to larger dot products than equally similar movies but with lower ratings).\n",
    "2. $ L = A^{T}A, L \\in \\mathbb{R}^{N \\times N}$ indicates column-column correlations (user-user similarities).\n",
    "3. $ A = UDV^{T}, U: (M \\times M), D: (M \\times N), V^{T}: (N \\times N) $; in our case: $ U: (6 \\times 6), D: (6 \\times 5), V^{T}: (5 \\times 5) $\n",
    "4. Performing SVD on the rating column would help us isolate some latent concepts. It will, for instance, yield a matrix mapping movies to their belonging to a particular type (or genre), as well as one mapping users to their affinities towards certain genres. Main goal: low-rank approximation of original matrix. Compute missing ratings to use for recommending movies.\n",
    "5. D contains the singular values $\\sigma_{i}$ on its diagonal. It's possible to keep all nonzero singular values, but it's generally more useful to just keep the K largest ones. In our case, we could consider keeping the first three or two.\n",
    "6. The matrix U can be seen as a description of every movie as a composition of some latent variables.\n",
    "7. The matrix V can be seen as a description of every user as a composition of some latent variables (e.g. affinities to certain movie genres)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A_imputed = np.nan_to_num(A)\n",
    "A_imputed[A_imputed == 0] = 5.5\n",
    "A_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def full_svd(matrix):\n",
    "    \"\"\"Utility which returns full SVD matrices.\n",
    "    \n",
    "    Works around the fact that numpy's SVD function returns the 'd'\n",
    "    as a vector of singular values, instead of a diagonal matrix.\n",
    "    \"\"\"\n",
    "    U, d, V = np.linalg.svd(matrix, full_matrices=True)\n",
    "    D = np.zeros(matrix.shape)\n",
    "    D[:d.shape[0],:d.shape[0]] = np.diag(d)\n",
    "    return U, D, V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "U, D, V = full_svd(A_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reconstruction = np.dot(U, np.dot(D, V))\n",
    "reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.allclose(A_imputed, reconstruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scatter_label(data, labels):\n",
    "    \"\"\"Helper function for pretty scatterplots.\"\"\"\n",
    "    plt.scatter(data[:, 0], data[:, 1], s=60)\n",
    "    for label, x, y in zip(labels, data[:, 0], data[:, 1]):\n",
    "        plt.annotate(\n",
    "            label, \n",
    "            xy = (x, y), xytext = (20, 20),\n",
    "            textcoords = 'offset points', ha = 'right', va = 'bottom',\n",
    "            bbox = dict(boxstyle = 'round, pad=0.5', fc = 'cyan', alpha = 0.5),\n",
    "            arrowprops = dict(arrowstyle = '->', connectionstyle = 'arc3,rad=0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "U_2 = U[:,:2]\n",
    "movie_labels = ['American Pie', 'Shrek', 'Titanic', 'The godfather', 'Avatar', 'Star Wars']\n",
    "scatter_label(U_2, movie_labels)\n",
    "    \n",
    "_ = plt.title(\"8. Representations of movies using first two singular values.\", \n",
    "              size=20, y=1.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can interpret the above plot's X axis as a (sort-of) degree of realism, while the Y axis can be seen as a distinction between drama (positive) and comedy (negative)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Idea: analyze massive data and detect cultists who enjoy cult\n",
    "# classics which some critics consider really bad (e.g. The Room, The Big Lebowski, etc.).\n",
    "\n",
    "# Idea: analyze stuff user hasn't yet seen. Avoid stuff with very high or very low ratings.\n",
    "\n",
    "V_2 = V[:,:2]\n",
    "user_labels = ['Ben', 'Tom', 'John', 'Fred', 'Jack']\n",
    "scatter_label(V_2, user_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "John and Jack prefer more serious movies, while Fred, Tom, and Ben are into comedies. Out of them, Fred seems to be the most well-rounded, but with still quite a strong inclination towards sci-fi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second singular value represents the comedy/drama division, while the first one seems to represent the degree of realism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A_approx = np.dot(U[:,:3], np.dot(D[:3,:], V))\n",
    "print(A_imputed)\n",
    "print(A_approx)\n",
    "error = np.linalg.norm(A_approx - A_imputed)\n",
    "print(\"Approximation error (frobenius): %f\" % error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bob wants to join the system!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Bob = np.array([[1, np.NaN, np.NaN, 6, np.NaN, 10]])\n",
    "Bob_imputed = np.nan_to_num(Bob)\n",
    "Bob_imputed[Bob_imputed == 0] = 5.5\n",
    "Bob_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO(andrei) Do this in a prettier way.\n",
    "A_bob_imputed = np.hstack((A_imputed, Bob_imputed.T))\n",
    "A_bob_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "U, D, V = full_svd(A_bob_imputed)\n",
    "scatter_label(U[:,:2], movie_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_labels.append('Bob')\n",
    "scatter_label(V[:,:2], user_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bob seems to be close to Fred, in that he also likes more serous movies, but he's even farther than the rest since he absolutely hates comedies such as American Pie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A_bob_approx = np.dot(U[:,:3], np.dot(D[:3,:], V))\n",
    "print(\"Approximate rating matrix including Bob:\\n\\n\", A_bob_approx, \"\\n\")\n",
    "error_frob = np.linalg.norm(A_approx - A_imputed, ord='fro')\n",
    "error_euclid = np.linalg.norm(A_approx - A_imputed, ord=2)\n",
    "\n",
    "print((\"Approximation errors after adding Bob to system:\\n\" +\n",
    "      \"\\t- Frobenius norm: %f\\n\" +\n",
    "      \"\\t- Euclidean norm: %f\\n\") % (error_frob, error_euclid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the highest predicted rating which was missing in Bob's original ratings in order to recommend him a movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get Bob's rating column!\n",
    "bob_index = user_labels.index('Bob')\n",
    "Bob_new_ratings = A_bob_approx[:, bob_index]\n",
    "\n",
    "# Keep track of the original row indices in the column...\n",
    "Bob_candidates = np.array([np.arange(Bob.shape[1]), Bob_new_ratings])\n",
    "# ...and only keep rows for movies Bob didn't see yet.\n",
    "Bob_candidates = Bob_candidates[:, np.isnan(Bob[0])]\n",
    "\n",
    "# Pick the row with the highest rating.\n",
    "best_entry = Bob_candidates[:, np.argmax(Bob_candidates[1,:])]\n",
    "# And then grab the movie index.\n",
    "best_index = int(best_entry[0])\n",
    "\n",
    "print(\"Bob should watch %s!\" % movie_labels[best_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In closing, Bob's ratings do affect our prediction system, since they add more information (and also a little bit more confusion, due to a slightly larger approximation error) to our data matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2: Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_ratings(data_file):\n",
    "    \"\"\"Loads the rating data from the specified file. \n",
    "    \n",
    "    Does not yet build the rating matrix. Use 'ratings_to_matrix' to do that.\n",
    "    Assumes the file has a header (which is ignored), and that the ratings are\n",
    "    then specified as 'rXXX_cXXX,X', where the 'X' blanks specify the row, the\n",
    "    column, and then the actual (integer) rating.\n",
    "    \"\"\"\n",
    "    ratings = []\n",
    "    with open(data_file, 'r') as file:\n",
    "        header = file.readline()\n",
    "        # print(\"Header: %s\" % header)\n",
    "        for line in file:\n",
    "            key, value_string = line.split(\",\")\n",
    "            rating = int(value_string)\n",
    "            row_string, col_string = key.split(\"_\")\n",
    "            row = int(row_string[1:])\n",
    "            col = int(col_string[1:])\n",
    "            \n",
    "            if rating < 1 or rating > 5:\n",
    "                raise ValueError(\"Found illegal rating value [%d].\" % rating)\n",
    "            \n",
    "            ratings.append((row - 1, col - 1, rating))\n",
    "            \n",
    "    return ratings\n",
    "\n",
    "def ratings_to_matrix(ratings, matrix_rows, matrix_cols):\n",
    "    \"\"\"Converts a list of ratings to a numpy matrix.\"\"\"\n",
    "    print(\"Building [%d x %d] rating matrix.\" % (matrix_rows, matrix_cols))\n",
    "    matrix = np.zeros([matrix_rows, matrix_cols])\n",
    "    for (row, col, rating) in ratings:\n",
    "        matrix[row, col] = rating\n",
    "        \n",
    "    print(\"Finished building rating matrix.\")\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Rows are users\n",
    "USER_COUNT = 10000\n",
    "\n",
    "# Columns are items\n",
    "ITEM_COUNT = 1000\n",
    "\n",
    "VALIDATION_RATIO = 0.1\n",
    "TRAINING_RATIO = 1 - VALIDATION_RATIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED = 0xC0FFEE\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_ratings = load_ratings('data/cf/data_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building [10000 x 1000] rating matrix.\n",
      "Finished building rating matrix.\n"
     ]
    }
   ],
   "source": [
    "data_matrix = ratings_to_matrix(all_ratings, USER_COUNT, ITEM_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have [1388107] data points.\n",
      "Will use [138810] data points for validation, and [1249297] for training.\n"
     ]
    }
   ],
   "source": [
    "all_ratings_count = len(all_ratings)\n",
    "print(\"We have [%d] data points.\" % all_ratings_count)\n",
    "\n",
    "validation_count = int(VALIDATION_RATIO * all_ratings_count)\n",
    "training_count = all_ratings_count - validation_count\n",
    "print(\"Will use [%d] data points for validation, and [%d] for training.\" %\n",
    "     (validation_count, training_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shuffle_split_data(all_data, training_count, validation_count):\n",
    "    \"\"\"Returns a split consisting of (training, validation) data, created\n",
    "    after shuffling the input data.\n",
    "    \"\"\"\n",
    "    to_shuffle = copy.copy(all_data)\n",
    "    random.shuffle(to_shuffle)\n",
    "    return to_shuffle[:training_count], to_shuffle[training_count:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building [10000 x 1000] rating matrix.\n",
      "Finished building rating matrix.\n",
      "Building [10000 x 1000] rating matrix.\n",
      "Finished building rating matrix.\n"
     ]
    }
   ],
   "source": [
    "train, validation = shuffle_split_data(all_ratings, training_count, validation_count)\n",
    "train_matrix = ratings_to_matrix(train, USER_COUNT, ITEM_COUNT)\n",
    "validation_matrix = ratings_to_matrix(validation, USER_COUNT, ITEM_COUNT)\n",
    "\n",
    "assert len(train_matrix[train_matrix != 0]) == training_count\n",
    "assert len(validation_matrix[validation_matrix != 0]) == validation_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score_predictions(prediction_matrix, validation_matrix):\n",
    "    \"\"\"Computes the RMSE score for the prediction matrix based\n",
    "    on the data points present in the validation matrix.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Want to compute RMSE just for nonzero validation elements.\n",
    "    mask = (validation_matrix != 0)\n",
    "    count = np.sum(mask)\n",
    "    actual = prediction_matrix[mask]\n",
    "    real = validation_matrix[mask]\n",
    "    \n",
    "    delta = np.abs(actual - real)\n",
    "    delta = delta * delta\n",
    "    delta = np.sum(delta)\n",
    "    \n",
    "    score = np.sqrt(delta / count)\n",
    "    return score\n",
    "\n",
    "\n",
    "def score_predictions_slow(prediction_matrix, validation_matrix):\n",
    "    s = 0\n",
    "    count = 0 #np.sum(validation_matrix > 0)\n",
    "    for row in range(validation_matrix.shape[0]):\n",
    "        for col in range(validation_matrix.shape[1]):\n",
    "            if validation_matrix[row, col] > 0:\n",
    "                delta = (validation_matrix[row, col] - prediction_matrix[row, col]) ** 2\n",
    "                s += delta\n",
    "                count += 1\n",
    "                \n",
    "    score = np.sqrt(s * 1.0 / count)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No-SVD RMSE: 1.1820\n"
     ]
    }
   ],
   "source": [
    "def predict_by_avg_item_rating(data):\n",
    "    # Assume every product has at least one rating.\n",
    "    # A product is represented by a column\n",
    "    nonzero = (data != 0)\n",
    "    rating_counts = nonzero.sum(1)\n",
    "    rating_sums = data.sum(1)\n",
    "    item_ratings = rating_sums / rating_counts\n",
    "    predictions = np.copy(data)\n",
    "    for col in range(data.shape[1]):\n",
    "        no_rating = (predictions[:, col] == 0)\n",
    "        predictions[no_rating, col] = item_ratings[col]\n",
    "\n",
    "    zero_pred = (predictions == 0)\n",
    "    assert np.sum(zero_pred) == 0\n",
    "    return predictions\n",
    "\n",
    "\n",
    "no_svd_result = predict_by_avg_item_rating(train_matrix)\n",
    "print(\"No-SVD RMSE: %.4f\" % score_predictions(no_svd_result, validation_matrix))\n",
    "# print(\"RMSE: %.4f\" % score_predictions_slow(no_svd_result, validation_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def svd_predict(data, k=290, sanity_check=False):\n",
    "    # Note: this function does not apply the 'sqrt(D)' pre-multiplication\n",
    "    # trick specified in the exercise sheet, as it led to a strange (and\n",
    "    # likely silly) bug.\n",
    "    imputed = predict_by_avg_item_rating(data)\n",
    "    U, d, V = np.linalg.svd(imputed, full_matrices=True)\n",
    "    # This ensures that our variables correspond with the notation in\n",
    "    # the slides and homework sheets.\n",
    "    V = V.T\n",
    "    D = np.zeros_like(imputed)\n",
    "    D[:d.shape[0], :d.shape[0]] = np.diag(d)\n",
    "#     U_prime = np.dot(U, np.sqrt(D))\n",
    "#     V_prime = np.dot(np.sqrt(D), V)\n",
    "    \n",
    "    if sanity_check:\n",
    "        reconstruction = np.dot(U, np.dot(D, V.T))\n",
    "        assert np.allclose(reconstruction, imputed)\n",
    "        \n",
    "#         rec_2 = np.dot(U_prime, V_prime.T)\n",
    "#         assert np.allclose(rec_2[:,:1000], imputed)\n",
    "    \n",
    "# There's probably a very simple explanation for why this is fucking up.\n",
    "\n",
    "#     U_prime_lim = U_prime[:,:k]\n",
    "#     V_prime_lim = V_prime[:,:k]\n",
    "\n",
    "#     k_prediction = np.dot(U_prime_lim, V_prime_lim.T)\n",
    "    U_lim = U[:,:k]\n",
    "    D_lim = D[:k, :]\n",
    "    V_lim = V[:, :]\n",
    "    k_prediction = np.dot(U_lim, np.dot(D_lim, V_lim.T))\n",
    "    k_prediction = k_prediction[:, :1000]\n",
    "    \n",
    "    return k_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reuse previous prediction\n",
    "imputed = no_svd_result\n",
    "\n",
    "U, d, V = np.linalg.svd(imputed, full_matrices=True)\n",
    "V = V.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D = np.zeros_like(imputed)\n",
    "D[:d.shape[0], :d.shape[0]] = np.diag(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A few sanity checks for various values of k (singular values kept).\n",
    "\n",
    "errors = []\n",
    "means = []\n",
    "ks = range(10, 1000, 25)\n",
    "for k in ks:\n",
    "    U_k = U[:, :k]\n",
    "    D_k = D[:k, :]\n",
    "    V_k = V[:, :]\n",
    "\n",
    "    recon_k = np.dot(U_k, np.dot(D_k, V_k.T))\n",
    "    fro = np.linalg.norm(recon_k - imputed)\n",
    "    errors.append(fro)\n",
    "    means.append(np.mean(recon_k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(ks, errors)\n",
    "plt.xlabel(\"kept singular values\")\n",
    "plt.ylabel(\"approximation error (Frobenius norm)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sanity\n",
    "plt.plot(ks, means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the singular value spectrum\n",
    "plt.plot(np.arange(15), d[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fun_prediction = svd_predict(train_matrix)\n",
    "fun_prediction_10 = svd_predict(train_matrix, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Item rating prediction score: %.8f\" % score_predictions(no_svd_result, validation_matrix))\n",
    "print(\"SVD prediction score (k=default): %.8f\" % score_predictions(fun_prediction, validation_matrix))\n",
    "print(\"SVD prediction score (k=10): %.8f\" % score_predictions(fun_prediction_10, validation_matrix))\n",
    "\n",
    "# Some sanity checks\n",
    "print(\"Should be 0: \", score_predictions(data_matrix, validation_matrix))\n",
    "print(\"Should be 0: \", score_predictions(validation_matrix, validation_matrix))\n",
    "print(\"Should be big: \", score_predictions(train_matrix, validation_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rmses = []\n",
    "for k in range(5, 20, 1):\n",
    "    U_lim = U[:,:k]\n",
    "    D_lim = D[:k, :]\n",
    "    V_lim = V[:,:]\n",
    "\n",
    "    k_prediction = np.dot(U_lim, np.dot(D_lim, V_lim.T))\n",
    "    k_prediction = k_prediction[:, :1000]\n",
    "    rmses.append((k, score_predictions(k_prediction, validation_matrix)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot([e[0] for e in rmses], [e[1] for e in rmses])\n",
    "plt.xlabel(\"Number of kept singular values $\\sigma$\")\n",
    "plt.ylabel(\"RMSE on validation set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for (k, err) in rmses:\n",
    "    print(\"%d: %.6f\" % (k, err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-validation (experimental)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1388107, 3)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV_FOLDS = 5\n",
    "folds = KFold(len(all_ratings), n_folds=CV_FOLDS, shuffle=True)\n",
    "\n",
    "# TODO(andrei) Implement predictions as a subclass of BaseEstimator\n",
    "# and/or RegressionEstimator.\n",
    "\n",
    "k = 3\n",
    "\n",
    "# A 2D array where every row is a data point. The first column specifies\n",
    "# the row in the data matrix where the rating belongs, the second column,\n",
    "# its column. The third one is the actual rating.\n",
    "all_ratings_np = np.array(all_ratings)\n",
    "all_ratings_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.66462851817\n",
      "3.66237906218\n",
      "Building [10000 x 1000] rating matrix.\n",
      "Finished building rating matrix.\n",
      "Building [10000 x 1000] rating matrix.\n",
      "Finished building rating matrix.\n",
      "Performing naive imputation...\n",
      "Performing SVD...\n",
      "SVD done.\n",
      "3.6639540381\n",
      "3.66507697517\n",
      "Building [10000 x 1000] rating matrix.\n",
      "Finished building rating matrix.\n",
      "Building [10000 x 1000] rating matrix.\n",
      "Finished building rating matrix.\n",
      "Performing naive imputation...\n",
      "Performing SVD...\n",
      "SVD done.\n",
      "3.66419297497\n",
      "3.66412123002\n",
      "Building [10000 x 1000] rating matrix.\n",
      "Finished building rating matrix.\n",
      "Building [10000 x 1000] rating matrix.\n",
      "Finished building rating matrix.\n",
      "Performing naive imputation...\n",
      "Performing SVD...\n",
      "SVD done.\n",
      "3.66372741304\n",
      "3.66598348108\n",
      "Building [10000 x 1000] rating matrix.\n",
      "Finished building rating matrix.\n",
      "Building [10000 x 1000] rating matrix.\n",
      "Finished building rating matrix.\n",
      "Performing naive imputation...\n",
      "Performing SVD...\n",
      "SVD done.\n",
      "3.66439018592\n",
      "3.6633323848\n",
      "Building [10000 x 1000] rating matrix.\n",
      "Finished building rating matrix.\n",
      "Building [10000 x 1000] rating matrix.\n",
      "Finished building rating matrix.\n",
      "Performing naive imputation...\n",
      "Performing SVD...\n",
      "SVD done.\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# We will not use 'svd_predict' and instead we will use a dirty trick\n",
    "# to significantly speed up our cross-validation scores.\n",
    "\n",
    "# For every fold, results will contain a list of len(ks) scores.\n",
    "# This is an unorthodox way of doing CV, but it's much faster since\n",
    "# we only do one SVD per fold, instead of one per (k * folds).\n",
    "results = []\n",
    "\n",
    "ks = range(1, 30, 1)\n",
    "for train_index, test_index in folds:\n",
    "    train = all_ratings_np[train_index]\n",
    "    test = all_ratings_np[test_index]\n",
    "    \n",
    "    print(np.mean(train[:,2]))\n",
    "    print(np.mean(test[:,2]))\n",
    "    \n",
    "    train_matrix = ratings_to_matrix(train, USER_COUNT, ITEM_COUNT)\n",
    "    test_matrix = ratings_to_matrix(test, USER_COUNT, ITEM_COUNT)\n",
    "    \n",
    "    print(\"Performing naive imputation...\")\n",
    "    imputed = predict_by_avg_item_rating(train_matrix)\n",
    "    print(\"Performing SVD...\")\n",
    "    U, d, V = np.linalg.svd(imputed, full_matrices=True)\n",
    "    print(\"SVD done.\")\n",
    "    V = V.T\n",
    "\n",
    "    D = np.zeros_like(imputed)\n",
    "    D[:d.shape[0], :d.shape[0]] = np.diag(d)\n",
    "\n",
    "    rmses = []\n",
    "    for k in ks:\n",
    "        U_k = U[:, :k]\n",
    "        D_k = D[:k, :]\n",
    "        V_k = V[:, :]\n",
    "        \n",
    "        k_prediction = np.dot(U_k, np.dot(D_k, V_k.T))\n",
    "        k_prediction = k_prediction[:, :1000]\n",
    "        rmses.append((k, score_predictions(k_prediction, test_matrix)))\n",
    "\n",
    "    results.append(rmses)\n",
    "    \n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv_rmses = []\n",
    "for index, k in enumerate(ks):\n",
    "    # print(\"k = %d\" % k)\n",
    "    score = 0\n",
    "    for fold in range(CV_FOLDS):\n",
    "        score += results[fold][index][1]\n",
    "        \n",
    "    avg_score = score / CV_FOLDS\n",
    "    cv_rmses.append(avg_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11c1a36d8>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEACAYAAACznAEdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11c202208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(ks, cv_rmses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x12386db38>]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEGCAYAAAB7DNKzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11c80a710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(ks[3:10], cv_rmses[3:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle test data output stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_result = svd_predict(data_matrix, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "def output_solution(solution_matrix):\n",
    "    submisson_template = load_ratings('data/cf/sampleSubmission.csv')\n",
    "    output = \"Id,Prediction\\n\"\n",
    "    for (row, col, _) in submisson_template:\n",
    "        output += \"r%d_c%d,%f\\n\" % (row + 1, col + 1, solution_matrix[row, col])\n",
    "                \n",
    "    return output\n",
    "\n",
    "def output_solution_to_file(solution_matrix, technique, output_root='out/cf'):\n",
    "    timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    file_name = \"submission-%s-%s.csv\" % (technique, timestr)\n",
    "    file_path = os.path.join(output_root, file_name)\n",
    "    with open(file_path, 'w') as output_file:\n",
    "        output_text = output_solution(solution_matrix)\n",
    "        output_file.write(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output_solution_to_file(test_result, \"vanilla\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
