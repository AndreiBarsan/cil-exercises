{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise session notes\n",
    "\n",
    "SVD is a genralization of eigenvalue decomposition.\n",
    "\n",
    "Given\n",
    "\n",
    "$$ A = U \\cdot D \\cdot V^{T} $$\n",
    "\n",
    "it holds that\n",
    "\n",
    "$$ \\left\\{ \\begin{array}{l}\n",
    "    A \\cdot V_i = d_i \\cdot u_i\\\\\n",
    "    A^{T} \\cdot U_i = d_i \\cdot v_i\n",
    "\\end{array}\\right. \n",
    "\\iff \n",
    "\\left\\{ \\begin{array}{l}\n",
    "    A \\cdot A^{T} \\cdot U_i = d_{i}^{2} u_{i} \\\\\n",
    "    A^{T} \\cdot A \\cdot V_i = d_{i}^{2} v_{i} \n",
    "\\end{array}\\right. .$$\n",
    "\n",
    "Exercise: prove that $r(\\tilde{A}) = 2$, where $\\tilde{A}_2 = U_2 \\cdot D_2 \\cdot V_2^T$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1 (SVD Theory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import copy\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 5)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-55db0d42a50d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "A = np.array([\n",
    "        [8, 7,      1, np.NaN, 4],\n",
    "        [9, 7,      2, 5,      6],\n",
    "        [1, 4,      9, np.NaN, 3],\n",
    "        [3, np.NaN, 8, 5,      4],\n",
    "        [np.NaN, 3, np.NaN, 9, 9],\n",
    "        [5, 1, 4, 10, np.NaN]\n",
    "    ])\n",
    "\n",
    "print(A.shape)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$A \\in \\mathbb{R}^{M \\times N}$.\n",
    "\n",
    "1. $ K = AA^{T}, K \\in \\mathbb{R}^{M \\times M} $ indicates row-row correlations (movie-movie similarities). Every element (i, j) is just the dot product between movies i and j. Could consider using cosine similarity instead of the dot product in order not to get distracted by the absolute rating when computing similarities (movie pairs with higher ratings lead to larger dot products than equally similar movies but with lower ratings).\n",
    "2. $ L = A^{T}A, L \\in \\mathbb{R}^{N \\times N}$ indicates column-column correlations (user-user similarities).\n",
    "3. $ A = UDV^{T}, U: (M \\times M), D: (M \\times N), V^{T}: (N \\times N) $; in our case: $ U: (6 \\times 6), D: (6 \\times 5), V^{T}: (5 \\times 5) $\n",
    "4. Performing SVD on the rating column would help us isolate some latent concepts. It will, for instance, yield a matrix mapping movies to their belonging to a particular type (or genre), as well as one mapping users to their affinities towards certain genres. Main goal: low-rank approximation of original matrix. Compute missing ratings to use for recommending movies.\n",
    "5. D contains the singular values $\\sigma_{i}$ on its diagonal. It's possible to keep all nonzero singular values, but it's generally more useful to just keep the K largest ones. In our case, we could consider keeping the first three or two.\n",
    "6. The matrix U can be seen as a description of every movie as a composition of some latent variables.\n",
    "7. The matrix V can be seen as a description of every user as a composition of some latent variables (e.g. affinities to certain movie genres)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A_imputed = np.nan_to_num(A)\n",
    "A_imputed[A_imputed == 0] = 5.5\n",
    "A_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def full_svd(matrix):\n",
    "    U, d, V = np.linalg.svd(matrix, full_matrices=True)\n",
    "    D = np.zeros(matrix.shape)\n",
    "    D[:d.shape[0],:d.shape[0]] = np.diag(d)\n",
    "    return U, D, V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "U, D, V = full_svd(A_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%precision 2\n",
    "U, D, V.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reconstruction = np.dot(U, np.dot(D, V))\n",
    "reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.allclose(A_imputed, reconstruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scatter_label(data, labels):\n",
    "    \"\"\"Helper function for pretty scatterplots.\"\"\"\n",
    "    plt.scatter(data[:, 0], data[:, 1], s=60)\n",
    "    for label, x, y in zip(labels, data[:, 0], data[:, 1]):\n",
    "        plt.annotate(\n",
    "            label, \n",
    "            xy = (x, y), xytext = (20, 20),\n",
    "            textcoords = 'offset points', ha = 'right', va = 'bottom',\n",
    "            bbox = dict(boxstyle = 'round, pad=0.5', fc = 'cyan', alpha = 0.5),\n",
    "            arrowprops = dict(arrowstyle = '->', connectionstyle = 'arc3,rad=0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "U_2 = U[:,:2]\n",
    "movie_labels = ['American Pie', 'Shrek', 'Titanic', 'The godfather', 'Avatar', 'Star Wars']\n",
    "scatter_label(U_2, movie_labels)\n",
    "    \n",
    "_ = plt.title(\"8. Representations of movies using first two singular values.\", \n",
    "              size=20, y=1.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can interpret the above plot's X axis as a (sort-of) degree of realism, while the Y axis can be seen as a distinction between drama (positive) and comedy (negative)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Idea: analyze massive data and detect cultists who enjoy cult\n",
    "# classics which some critics consider really bad (e.g. The Room, The Big Lebowski, etc.).\n",
    "\n",
    "# Idea: analyze stuff user hasn't yet seen. Avoid stuff with very high or very low ratings.\n",
    "\n",
    "V_2 = V[:,:2]\n",
    "user_labels = ['Ben', 'Tom', 'John', 'Fred', 'Jack']\n",
    "scatter_label(V_2, user_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "John and Jack prefer more serious movies, while Fred, Tom, and Ben are into comedies. Out of them, Fred seems to be the most well-rounded, but with still quite a strong inclination towards sci-fi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second singular value represents the comedy/drama division, while the first one seems to represent the degree of realism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A_approx = np.dot(U[:,:3], np.dot(D_full[:3,:], V))\n",
    "print(A_imputed)\n",
    "print(A_approx)\n",
    "error = np.linalg.norm(A_approx - A_imputed)\n",
    "print(\"Approximation error (frobenius): %f\" % error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bob wants to join the system!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Bob = np.array([[1, np.NaN, np.NaN, 6, np.NaN, 10]])\n",
    "Bob_imputed = np.nan_to_num(Bob)\n",
    "Bob_imputed[Bob_imputed == 0] = 5.5\n",
    "Bob_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO(andrei) Do this in a prettier way.\n",
    "A_bob_imputed = np.hstack((A_imputed, Bob_imputed.T))\n",
    "A_bob_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "U, D, V = full_svd(A_bob_imputed)\n",
    "scatter_label(U[:,:2], movie_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_labels.append('Bob')\n",
    "scatter_label(V[:,:2], user_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bob seems to be close to Fred, in that he also likes more serous movies, but he's even farther than the rest since he absolutely hates comedies such as American Pie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A_bob_approx = np.dot(U[:,:3], np.dot(D[:3,:], V))\n",
    "print(\"Approximate rating matrix including Bob:\\n\\n\", A_bob_approx, \"\\n\")\n",
    "error_frob = np.linalg.norm(A_approx - A_imputed, ord='fro')\n",
    "error_euclid = np.linalg.norm(A_approx - A_imputed, ord=2)\n",
    "\n",
    "print((\"Approximation errors after adding Bob to system:\\n\" +\n",
    "      \"\\t- Frobenius norm: %f\\n\" +\n",
    "      \"\\t- Euclidean norm: %f\\n\") % (error_frob, error_euclid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the highest predicted rating which was missing in Bob's original ratings in order to recommend him a movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get Bob's rating column!\n",
    "bob_index = user_labels.index('Bob')\n",
    "Bob_new_ratings = A_bob_approx[:, bob_index]\n",
    "\n",
    "# Keep track of the original row indices in the column...\n",
    "Bob_candidates = np.array([np.arange(Bob.shape[1]), Bob_new_ratings])\n",
    "# ...and only keep rows for movies Bob didn't see yet.\n",
    "Bob_candidates = Bob_candidates[:, np.isnan(Bob[0])]\n",
    "\n",
    "# Pick the row with the highest rating.\n",
    "best_entry = Bob_candidates[:, np.argmax(Bob_candidates[1,:])]\n",
    "# And then grab the movie index.\n",
    "best_index = int(best_entry[0])\n",
    "\n",
    "print(\"Bob should watch %s!\" % movie_labels[best_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In closing, Bob's ratings do affect our prediction system, since they add more information (and also a little bit more confusion, due to a slightly larger approximation error) to our data matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2: Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_ratings(data_file):\n",
    "    ratings = []\n",
    "    with open(data_file, 'r') as file:\n",
    "        header = file.readline()\n",
    "        print(\"Header: %s\" % header)\n",
    "        for line in file:\n",
    "            key, value_string = line.split(\",\")\n",
    "            rating = int(value_string)\n",
    "            row_string, col_string = key.split(\"_\")\n",
    "            row = int(row_string[1:])\n",
    "            col = int(col_string[1:])\n",
    "            \n",
    "            ratings.append((row - 1, col - 1, rating))\n",
    "            \n",
    "    print(\"Finished loading ratings.\")\n",
    "    return ratings\n",
    "\n",
    "def ratings_to_matrix(ratings, matrix_rows, matrix_cols):\n",
    "    print(\"Building [%d x %d] rating matrix.\" % (matrix_rows, matrix_cols))\n",
    "    matrix = np.zeros([matrix_rows, matrix_cols])\n",
    "    for (row, col, rating) in ratings:\n",
    "        matrix[row, col] = rating\n",
    "        \n",
    "    print(\"Finished building rating matrix.\")\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Rows are items\n",
    "ITEM_COUNT = 1000\n",
    "\n",
    "# Columns are users\n",
    "USER_COUNT = 10000\n",
    "\n",
    "VALIDATION_RATIO = 0.1\n",
    "TRAINING_RATIO = 1 - VALIDATION_RATIO\n",
    "\n",
    "RANDOM_SEED = 0xC0FFEE\n",
    "\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Header: Id,Prediction\n",
      "\n",
      "Finished loading ratings.\n"
     ]
    }
   ],
   "source": [
    "all_ratings = load_ratings('data/cf/data_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building [10000 x 1000] rating matrix.\n",
      "Finished building rating matrix.\n"
     ]
    }
   ],
   "source": [
    "data_matrix = ratings_to_matrix(all_ratings, USER_COUNT, ITEM_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have [1388107] data points.\n",
      "Will use [138810] data points for validation, and [1249297] for training.\n"
     ]
    }
   ],
   "source": [
    "all_ratings_count = len(all_ratings)\n",
    "print(\"We have [%d] data points.\" % all_ratings_count)\n",
    "\n",
    "validation_count = int(VALIDATION_RATIO * all_ratings_count)\n",
    "training_count = all_ratings_count - validation_count\n",
    "print(\"Will use [%d] data points for validation, and [%d] for training.\" %\n",
    "     (validation_count, training_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shuffle_split_data(all_data, training_count, validation_count):\n",
    "    \"\"\"Returns a split consisting of (training, validation) data, created\n",
    "    after shuffling the input data.\n",
    "    \"\"\"\n",
    "    to_shuffle = copy.copy(all_data)\n",
    "    random.shuffle(to_shuffle)\n",
    "    return to_shuffle[:training_count], to_shuffle[training_count:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building [10000 x 1000] rating matrix.\n",
      "Finished building rating matrix.\n",
      "Building [10000 x 1000] rating matrix.\n",
      "Finished building rating matrix.\n"
     ]
    }
   ],
   "source": [
    "train, validation = shuffle_split_data(all_ratings, training_count, validation_count)\n",
    "train_matrix = ratings_to_matrix(train, USER_COUNT, ITEM_COUNT)\n",
    "validation_matrix = ratings_to_matrix(validation, USER_COUNT, ITEM_COUNT)\n",
    "\n",
    "assert len(train_matrix[train_matrix != 0]) == training_count\n",
    "assert len(validation_matrix[validation_matrix != 0]) == validation_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_ratings = r[r != 0]\n",
    "len(actual_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
